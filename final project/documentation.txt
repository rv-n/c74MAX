title: Sound Spherize

Artist’s Statement
I wanted to make a patch that contains an audiovisual work using objects that change in real time through sound

Parts List

1 PC / Windows10 operating system (64 bit) / 1000$ or less
1 graphic card / Nvidia GTX 1070 (or less) / 400$
1 audio card / integrated laptop sound card / 0$
1 external monitor / monitor for fullscreen display while working with the patch / 100$ or less

Technical Description
The patch is structured in two basic parts: audio and video.
Audio part is structured in the loading of external audio files and possibility of simultaneously acquiring audio from sources outside; sub-patch containing a random particle selector of the loaded sample was added to randomize sequence; possibility to calculate average bpm frequency by pressing the space key several times; sonogram object has been added to monitor incoming frequencies.
Video part is structured in external window that can be moved into another monitor for the fullscreen while working on parameters of the patch; it contains various graphic elements, including the sphere which modulates raised texture generated by bfg object and density by the width of the incoming volume and synchronized with calculated bpm; below a equalizer generated by multislider that reacts to the alpha channel of bfg object; spherical context was created where a 360 image was applied.
Parameters that can be modified in real time are: change of alpha textures for object jit.bfg, materials of the sphere, type of rendering of sphere, diameter amplitude, sphere intensity of bfg texture, external 360 image, rotation degrees of the ​​context and speed, switch auto rotation.
Patch contains various comments alongside the key points.

Audio Logic Part
we start from the "ezadc~" audio input from which we have the main input to the bfg texture modulation through the "convert signal" sub-patch whose output value directly modifies the "weight" parameter of the bfg object, the parameter "s color" and the scale of the bfg texture; the "sfplay~" object was added to have the ability to load external audio files directly into Max and change the frequency of specific fragments using the "randomize" sub-patch, and the "noise gen" sub-patch was added which contains a series of "cycle~", "tri~" and "kink~" signals, modulated in non-linear sequence; a selector for the space key has been added through which we can insert a specific "time" in the "clicker" sub-patch which allows us to synchronize in bpm ("synch" sub-patch) the bfg object and the audio fragment randomizer , every 5 seconds of inactivity the bpm average calculation timer is reset.

Video Logic Part
to the "jit.bfg" object was added the "jit.normalize" object to increase the white areas of the texture, then the "slide_up" and "slide_down" parameters was modified to react more smoothly to the change in audio frequency; the multislider is calculated using "jit.op" operators to translate the alpha channel of bfg into heights for the equalizer ("jit.gl.graph" x2 sub-patch); the sphere in "jit.gl.gridshape" considers the texture from bfg as a surface height map calculating the black as ground point and the white the maximum height point; inside the object jit.gen there are the parameters "swiz" to remake the components of the vectors, combining the texture with the amplitude of the audio signal (bfg + sub-patch "convert signal"); colors have been assigned to the equalizer which change according to the amount of incoming sound ("s color"), added two lights at the scene ("light" sub-patch), added a camera ("jit.gl.camera"), added a switch to rotate the environment 360 ("s spin") and a selector for materials (black and gray) of the sphere, angle of rotation ("s degrees") and speed of rotation ("s phase"), the loading of the external image 360 ​​takes place in the sub-patch "texture env", while the application to the sphere of context (the larger one) is in the "360" sub-patch, the rotation of each object is conducted by the "autorotate" sub-patch.

Credits
the "env.jpg" file of the 360 enviroment context can be found at "https://adastra.fit.edu/blog/uncategorized/astrophysics/" (reference in the patch).
the audio file "drm_loop02.wav" and the piano song in the demo video are owned by Flavio Severino.

Future Work
the idea of the sound reactive sphere was suggested by my own A/V work a few years ago: Wraithmachine (https://vimeo.com/208282868), implementing a more solid and better planned version thanks to your course, so I don't think I will develop this project further.

Self-assessment
Art / aesthetics of result
- Evaluation: real-time modeling fluidity of the sphere and implementation of a 360 context, the equalizer responds well to the bfg map
- Comparison to intention: the artistic production found is similar to what I had in mind at the time of departure, perhaps it is possible to increase the three-dimensional effect of the context 360

Max Programming
-Evaluation: the sound of the "randomize" function have a perfectly non-linear function, but do not move fragments in the time parameter (ms)
-Comparison to intention: I managed to create a patch that I hope will be clear and legible, even if not all the elements are classified in sub-patches, being able to create some confusion when reading the work area

Implementation of additional project elements
- Evaluation: limited choice of materials, (perhaps the possibility of choosing personal materials could be added)
- Comparison to intention: there are many parameters that can be changed manually to be able to customize the A/V experience, however it seems (especially for the audio part) that the "play/stop" and the transition to "randomize" remain a bit cumbersome
